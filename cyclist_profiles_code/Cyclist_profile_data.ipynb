{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cyclist_profile_data.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOqWKeO5/fqJLXdJtnG3yND",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pierre-brendan/PelotonIQ/blob/master/cyclist_profiles_code/Cyclist_profile_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKDEMxGW9tnw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import packages\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# start with non-looped method to get profiles\n",
        "url = 'https://www.procyclingstats.com/rider/dylan-groenewegen'\n",
        "html = requests.get(url).text\n",
        "soup = BeautifulSoup(html, 'html5lib')\n",
        "\n",
        "# GC method\n",
        "spans = soup.find_all('li', {\"class\": \"gc\"})\n",
        "gc = [span.get_text() for span in spans]\n",
        "gc = ''.join(gc)\n",
        "gc = re.sub('GC', '', gc)\n",
        "\n",
        "# Classic\n",
        "spans = soup.find_all('li', {\"class\": \"classic\"})\n",
        "classic = [span.get_text() for span in spans]\n",
        "classic = ''.join(classic)\n",
        "classic = re.sub('One day races', '', classic)\n",
        "\n",
        "# Time trial\n",
        "spans = soup.find_all('li', {\"class\": \"tt\"})\n",
        "tt = [span.get_text() for span in spans]\n",
        "tt = ''.join(tt)\n",
        "tt = re.sub('Time trial', '', tt)\n",
        "\n",
        "# Sprint\n",
        "spans = soup.find_all('li', {\"class\": \"sprint\"})\n",
        "sprint = [span.get_text() for span in spans]\n",
        "sprint = ''.join(sprint)\n",
        "sprint = re.sub('Sprint', '', sprint)\n",
        "\n",
        "# Climber\n",
        "spans = soup.find_all('li', {\"class\": \"climber\"})\n",
        "climber = [span.get_text() for span in spans]\n",
        "climber = ''.join(climber)\n",
        "climber = re.sub('Climber', '', climber)\n",
        "\n",
        "# Rider\n",
        "spans = soup.find_all('h1')\n",
        "lines = [span.get_text() for span in spans]\n",
        "rider2 = lines\n",
        "rider2 = ''.join(rider2)\n",
        "rider2 = re.sub(\"».*$\", \"\", rider2)\n",
        "rider2 = re.sub(\"  \", \"\", rider2)\n",
        "rider2 = str.strip(rider2)\n",
        "\n",
        "# Team\n",
        "team2 = lines\n",
        "team2 = ''.join(team2)\n",
        "team2 = re.sub('$.»*', '', team2)\n",
        "try: \n",
        "  team2 =  team2.split('»')[1]\n",
        "except Exception:\n",
        "  team2 = \"\"\n",
        "print(team2) \n",
        "\n",
        "# Age\n",
        "spans = soup.find_all('div', {\"class\": \"rdr-info-cont\"})\n",
        "lines = [span.get_text() for span in spans]\n",
        "age = ''.join(lines)\n",
        "try: \n",
        "  age = age[age.find(\"(\")+1:age.find(\")\")]\n",
        "except Exception:\n",
        "  age = \"\"\n",
        "print(age) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SuLbh0t10cQO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "67bceb70-8552-45a6-d4ba-a172447a198e"
      },
      "source": [
        "rider2 = str.strip(rider2)\n",
        "rider2 "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Dylan Groenewegen'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOQvWK9c7N5b",
        "colab_type": "text"
      },
      "source": [
        "Looped version"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOsR24zGzHhe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Mount drive to get cyclist links\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrS1EvX67JQx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import packages\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import pandas as pd\n",
        "import re\n",
        "from datetime import date\n",
        "\n",
        "# Load in cyclist links for loop\n",
        "df1 = pd.read_csv('/content/drive/My Drive/cycling_data/cyclist_links.csv')\n",
        "urls = df1['proper_link']\n",
        "\n",
        "#urls = ['https://www.procyclingstats.com/rider/alejandro-valverde', 'https://www.procyclingstats.com/rider/julian-alaphilippe']\n",
        "appended_data = []\n",
        "\n",
        "for i in urls:\n",
        "  print(i)\n",
        "  # start with non-looped method to get profiles\n",
        "  url = i\n",
        "  html = requests.get(url).text\n",
        "  soup = BeautifulSoup(html, 'html5lib')\n",
        "\n",
        "  # GC method\n",
        "  spans = soup.find_all('li', {\"class\": \"gc\"})\n",
        "  gc = [span.get_text() for span in spans]\n",
        "  gc = ''.join(gc)\n",
        "  gc = re.sub('GC', '', gc)\n",
        "\n",
        "  # Classic\n",
        "  spans = soup.find_all('li', {\"class\": \"classic\"})\n",
        "  classic = [span.get_text() for span in spans]\n",
        "  classic = ''.join(classic)\n",
        "  classic = re.sub('One day races', '', classic)\n",
        "\n",
        "  # Time trial\n",
        "  spans = soup.find_all('li', {\"class\": \"tt\"})\n",
        "  tt = [span.get_text() for span in spans]\n",
        "  tt = ''.join(tt)\n",
        "  tt = re.sub('Time trial', '', tt)\n",
        "\n",
        "  # Sprint\n",
        "  spans = soup.find_all('li', {\"class\": \"sprint\"})\n",
        "  sprint = [span.get_text() for span in spans]\n",
        "  sprint = ''.join(sprint)\n",
        "  sprint = re.sub('Sprint', '', sprint)\n",
        "\n",
        "  # Climber\n",
        "  spans = soup.find_all('li', {\"class\": \"climber\"})\n",
        "  climber = [span.get_text() for span in spans]\n",
        "  climber = ''.join(climber)\n",
        "  climber = re.sub('Climber', '', climber)\n",
        "\n",
        "  # Rider\n",
        "  spans = soup.find_all('h1')\n",
        "  lines = [span.get_text() for span in spans]\n",
        "  rider2 = lines\n",
        "  rider2 = ''.join(rider2)\n",
        "  rider2 = re.sub(\"».*$\", \"\", rider2)\n",
        "  rider2 = re.sub(\"  \", \"\", rider2)\n",
        "  rider2 = str.strip(rider2)\n",
        "\n",
        "  # Team\n",
        "  team2 = lines\n",
        "  team2 = ''.join(team2)\n",
        "  team2 = re.sub('$.»*', '', team2)\n",
        "  try: \n",
        "    team2 =  team2.split('»')[1]\n",
        "  except Exception:\n",
        "     team2 = \"\"\n",
        "  team2 = str.strip(team2)\n",
        "\n",
        "  # Age    \n",
        "  spans = soup.find_all('div', {\"class\": \"rdr-info-cont\"})\n",
        "  lines = [span.get_text() for span in spans]\n",
        "  age = ''.join(lines)\n",
        "  try: \n",
        "    age = age[age.find(\"(\")+1:age.find(\")\")]\n",
        "  except Exception:\n",
        "    age = \"\"\n",
        "\n",
        "  data = pd.DataFrame(\n",
        "    {'Rider': [rider2],\n",
        "     'Team': [team2],\n",
        "     'GC': [gc],\n",
        "     'TT': [tt],\n",
        "     'Sprint': [sprint],\n",
        "     'Climber': [climber],\n",
        "     'Classic': [classic],\n",
        "     'Age': [age]\n",
        "    })\n",
        "\n",
        "  # store DataFrame in list\n",
        "  appended_data.append(data)\n",
        "\n",
        "# see pd.concat documentation for more info\n",
        "appended_data = pd.concat(appended_data)\n",
        "\n",
        "# add crawl date\n",
        "appended_data['crawl_date'] = date.today()\n",
        "\n",
        "# Save the data file\n",
        "appended_data.to_csv('rider_data.csv', index = False)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}